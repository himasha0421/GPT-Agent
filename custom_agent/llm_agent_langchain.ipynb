{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are building a langchain conversational agent\n",
    "from langchain import OpenAI\n",
    "from langchain.agents import initialize_agent , Tool\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "import streamlit   as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate the nth fibonacci number\n",
    "def fib(n) :\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return ( fib( n-1 ) + fib( n-2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function sorts the input string alphabetically\n",
    "def sort_string( string ):\n",
    "    return ''.join( sorted( string ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defien a function to trun the word into an encrypted word\n",
    "def encrypt(word):\n",
    "    encrypted_word = ''\n",
    "    for letter in word:\n",
    "        encrypted_word += chr( ord( letter ) + 1 )\n",
    "    return encrypted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to encrypted word into decrypt mode\n",
    "def decrypt(word):\n",
    "    decrypted_word = ''\n",
    "    for letter in word :\n",
    "        decrypted_word += chr( ord( letter ) -1 )\n",
    "    return decrypted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def check_balance(word):\n",
    "    answer= word.split(\"-->\")[-1]\n",
    "    msisdn = [ str(s) for s in re.findall(r'\\b\\d+\\b',  answer )]\n",
    "\n",
    "    return \"Number : {} Current Balance is : {}\".format( msisdn , 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "\n",
    "    Tool(\n",
    "        name = 'Fibonacci' ,\n",
    "        func= lambda n : str( fib(int(n)) ) ,\n",
    "        description=\"use when you want to calculate the nth fibonacci number\",\n",
    "        #return_direct=True\n",
    "    ) ,\n",
    "    Tool(\n",
    "        name='Sort String' ,\n",
    "        func=lambda string : sort_string(string) ,\n",
    "        description=\"use when you want to sort  a string alphabetically\",\n",
    "        #return_direct=True\n",
    "    ),\n",
    "    Tool(\n",
    "        name='Encrypt',\n",
    "        func=lambda word : encrypt(word),\n",
    "        description=\"use when you want to encrypt a word\",\n",
    "        #return_direct=True\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Decrypt\",\n",
    "        func= lambda word : decrypt(word) ,\n",
    "        description=\"use when you want to decrypt a word\",\n",
    "        #return_direct=True\n",
    "    ) ,\n",
    "    # add tool to check balance\n",
    "    Tool(\n",
    "        name = \"Check Account Balance\" ,\n",
    "        func =  lambda msisdn : check_balance( msisdn ) ,\n",
    "        description=\"use when you want to know about the account balance\",\n",
    "        #return_direct=True \n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "api_key =  os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the chat memeory buffer\n",
    "memory = ConversationBufferMemory( memory_key='chat_history' ) # --> try other memeory types as well\n",
    "# define the openai LLM ]\n",
    "llm =  OpenAI( temperature= 0.1 , verbose=True )\n",
    "agent_chain =  initialize_agent(  tools=tools ,\n",
    "                                   llm= llm ,\n",
    "                                   agent= \"conversational-react-description\" ,\n",
    "                                   memory  = memory ,\n",
    "                                   verbose = True   # verbose handle the agents though process  \n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the steamlit app\n",
    "st.header( \":blue[Langchain Chatbot with agent/tools and memeory] :sunglasses:\" ) # short term memory no embedd vector store\n",
    "user_input =  st.text_input(\"You: \")\n",
    "# initialize the memory buffer\n",
    "if \"memeory\" not in st.session_state :\n",
    "    st.session_state['memory'] = \"\"\n",
    "\n",
    "# add stremalit button\n",
    "if st.button(\"Submit\"):\n",
    "\n",
    "    # execute the langchain agent\n",
    "    st.markdown( agent_chain.run( input =  user_input ) )\n",
    "    # print the memeory buffer\n",
    "    # add the conversation history to memeory buffer\n",
    "    st.session_state['memory'] += memory.buffer\n",
    "    print( st.session_state['memory'] )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fr_tenant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db83642f18eb79f15dafa6211d6596dd13e18c3dcd3fc33f9a1b799c5217feeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
